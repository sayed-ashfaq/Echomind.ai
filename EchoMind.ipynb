{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ceebae6f-64f6-4de8-9543-2f5f35ea7b22",
   "metadata": {},
   "source": [
    "# ðŸš€ Project: EchoMind - My GenAI Morning Productivity Assistant\n",
    "\n",
    "## ðŸŽ¯ My Long-Term Vision:\n",
    "Build a JARVIS-like AI assistant that understands my habits, remembers my progress, and helps me grow every day toward my dream roles in GenAI and Robotics.\n",
    "\n",
    "---\n",
    "\n",
    "## ðŸ“… Current Goal (April 2025):\n",
    "âœ… Build a working MVP of EchoMind using:\n",
    "- âœ… Jupyter notebook + OpenAI API\n",
    "- âœ… Task generator using  based on my LongTerm fixed Goal and memory till he have done.\n",
    "- âœ… AI related news and articles - Twitter updates\n",
    "- âœ… Memory system (semantic + episodic)\n",
    "- âœ… Reflections & tracking\n",
    "- âœ… Daily affirmations like the one below<br>\n",
    "**Can be customizable for specific users**\n",
    "---\n",
    "\n",
    "## ðŸ§  This Project Will Help Me:\n",
    "- Master prompt engineering and GPT integration\n",
    "- Understand memory systems in AI (RAG)\n",
    "- Learn to think like a product builder\n",
    "- Move one step closer to a GenAI role ðŸš€\n",
    "\n",
    "---\n",
    "\n",
    "## ðŸ§­ When I Feel:\n",
    "### ðŸ˜ž \"This is too simple\":\n",
    "âž¡ï¸ **Reminder**: MVPs are simple by design. Focus on *finishing*, not *perfecting*.\n",
    "\n",
    "### ðŸ¤¯ \"This idea may not succeed\":\n",
    "âž¡ï¸ **Reminder**: No one can predict success. But building this will make me 10x smarter and closer to my dream.\n",
    "\n",
    "### ðŸ˜µ \"Iâ€™m deviating\":\n",
    "âž¡ï¸ **Ask Yourself**: \n",
    "- â€œDoes this help me master GenAI?â€\n",
    "- â€œDoes this align with my vision?â€\n",
    "\n",
    "âœ… If yes, continue. âŒ If no, realign.\n",
    "\n",
    "---\n",
    "\n",
    "## ðŸŒŸ Daily Affirmation\n",
    "> â€œBig things are built by showing up every day. This project is my gym.â€\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a34f8e20-876c-4f3a-842e-99b8cc5e25a4",
   "metadata": {},
   "source": [
    "\n",
    "## Recommended Python Packages\n",
    "\n",
    "To work effectively with LangChain, I recommend these Python packages:\n",
    "\n",
    "1. **langchain**: The core framework\n",
    "2. **openai**: For using OpenAI models\n",
    "3. **huggingface_hub**: For Hugging Face models\n",
    "4. **chromadb**: For vector storage\n",
    "5. **faiss-cpu**: For vector search\n",
    "6. **tiktoken**: For token counting\n",
    "7. **pypdf**: For PDF document loading\n",
    "8. **pandas**: For data manipulation\n",
    "9. **numpy**: For numerical operations\n",
    "10. **requests**: For API calls\n",
    "\n",
    "You can install these packages using conda or pip within your Jupyter environment.\n",
    "\n",
    "For more complex applications, LangChain supports document loading, embedding, vector stores, and agent tools that can be integrated into your workflows."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e41dd754-1739-4117-bdc3-9a94cf761245",
   "metadata": {},
   "source": [
    "### How to load Env variables\n",
    "1. Create a .env file using command in cmd - echo. > .env\n",
    "2. just enter the variables and load them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f29f3e03-8ebc-4dd8-9c27-012fe6173bf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install langchain\n",
    "# pip install -U langchain-openai\n",
    "# # pip install prompts\n",
    "# %pip install -U langchain-community langgraph langchain-anthropic tavily-python langgraph-checkpoint-sqlite"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c5ab18c-ba5a-4c6a-a777-47b7d18d5ec6",
   "metadata": {},
   "source": [
    "### Mastering the APIs along with LangChain\n",
    "- First let's start with basic use case of Grok API then let's go forward.\n",
    "- "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1d7ca7c9-a078-470f-903f-caabd116bc5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "As the moonlight sparkled on the tranquil lake, a gentle unicorn named Luma danced under the stars, spreading dreams of magic and wonder to all who slept nearby.\n"
     ]
    }
   ],
   "source": [
    "# from openai import OpenAI\n",
    "# client = OpenAI()\n",
    "\n",
    "# response = client.responses.create(\n",
    "#     model=\"gpt-4o-mini\",\n",
    "#     input=\"Write a one-sentence bedtime story about a unicorn.\"\n",
    "# )\n",
    "\n",
    "# print(response.output_text)\n",
    "\n",
    "## OPEN AI GPT IS WORKING JUST FINE - ALWAYS USE MODEL= \"gpt-4o-mini\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "910bda46-c55f-4dd6-9244-b7ef5f1a8cf4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "My OpenAI Key is: k-proj-wU...\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import openai\n",
    "\n",
    "_= load_dotenv()  # Loads .env file into environment variables\n",
    "\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "print(f\"My OpenAI Key is: {openai.api_key[1:10]}...\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5c8bae59-3475-4532-88c0-25118124dd9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A Jupyter notebook where you can:\n",
    "\n",
    "## Add goals (e.g., â€œLearn Python in 3 monthsâ€).\n",
    "## Log progress (e.g., â€œDid a Python exercise todayâ€).\n",
    "## Get daily goal ideas from an AI (e.g., â€œDo 2 Python exercises, read 1 chapterâ€).\n",
    "## Store everything in a simple database (like a digital notebook).\n",
    "## See your goals and progress in tables."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1b47c37-e24f-4eb2-b47c-e77a11d7fa92",
   "metadata": {},
   "source": [
    "### LangChain from the DeepLearning.AI\n",
    "#### Learning Basics of using LangChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ad2211d3-4caf-4f2b-9bb0-44a43cea7c43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-04-14\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "#get the current date\n",
    "current_date = datetime.datetime.now().date()\n",
    "print(current_date)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7980c063-545f-4f48-b139-bed5cec65d5e",
   "metadata": {},
   "source": [
    "### Chat API: OpenAI \n",
    "Getting responses from the AI, using langchain\n",
    "\n",
    "### Agenda - Learn langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8b9a6a28-137a-4969-97e1-625ba58b6494",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_model = \"gpt-4o-mini\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5c121034-fd0e-4fbf-9e63-8b4936805205",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# pip install -qU \"langchain[openai]\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "005d6695-c133-40ee-bce7-98089922a014",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip list  ## CODE TO GET THS LIST OF MODULES PIP INSTALLED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4acd05cf-d073-4ba9-93ea-9239ec9ed3cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import init_chat_model\n",
    "\n",
    "model = init_chat_model(model = llm_model, model_provider= \"openai\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c5b6be40-da41-4477-8f3f-3c53adbd374d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hello! How can I assist you today?'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "response = model.invoke([HumanMessage(content= \"hi!\")])\n",
    "response.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "157e0e51-9d6f-429d-a84b-831cd29f1760",
   "metadata": {},
   "source": [
    "**Tool Calling - using .bind_tools to give the knowledge of these tools to the model.**\n",
    "1. One method is using TavilySearchResults - first 1000 searches are free but need to enter the card details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8eb50b52-f453-4c71-a724-1614a4abdd48",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.tools import tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a79563ee-43f1-488a-acdd-ffe1ed52fadf",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def create_todolist(tasks_completed: str, subject: str, roadmap: str) -> str:\n",
    "    \"\"\"Create a daily todo list based on the tasks completed till now and roadmap provided for the user.\"\"\"\n",
    "    # Placeholder response - in real app would send email\n",
    "    return f\"Create a daily todo list based on the {tasks_completed} till now based on {roadmap} provided for the user.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0c70d7ad-9e53-445b-93dc-2a3bf76f1621",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def set_priorities():\n",
    "    \"\"\"set priorities to make the day succesful\"\"\"\n",
    "    # Placeholder response - in real app would check calendar and schedule\n",
    "    return \"Just a testing, Meeting '{subject}' scheduled for {preferred_day} with {len(attendees)} attendees, print as it was.\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae7818af-8372-484a-8cb2-f0be27adb438",
   "metadata": {},
   "source": [
    "**Buffer tools**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "0670929d-f873-4195-8ddd-6d5b0ce6946c",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def schedule_meeting(\n",
    "    attendees: list[str], \n",
    "    subject: str, \n",
    "    duration_minutes: int, \n",
    "    preferred_day: str\n",
    ") -> str:\n",
    "    \"\"\"Schedule a calendar meeting.\"\"\"\n",
    "    # Placeholder response - in real app would check calendar and schedule\n",
    "    return f\"Meeting '{subject}' scheduled for {preferred_day} with {len(attendees)} attendees\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "378265ed-8082-40ee-98c7-b2bf53421285",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def check_calendar_availability(day: str) -> str:\n",
    "    \"\"\"Check calendar availability for a given day.\"\"\"\n",
    "    # Placeholder response - in real app would check actual calendar\n",
    "    return f\"Available times on {day}: 9:00 AM, 2:00 PM, 4:00 PM\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0ede3f6e-e479-431a-b6b4-a85d0e231fff",
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [create_todolist, set_priorities]\n",
    "\n",
    "model_with_tools = model.bind_tools(tools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8d0519e5-c3b6-445c-be7d-66ee8e4514e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ContentString: Hello! How can I assist you today?\n",
      "ToolCalls: []\n"
     ]
    }
   ],
   "source": [
    "response = model_with_tools.invoke([HumanMessage(content=\"Hi!\")])\n",
    "\n",
    "print(f\"ContentString: {response.content}\")\n",
    "print(f\"ToolCalls: {response.tool_calls}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "35c682b5-7944-48f8-83df-41a0849771e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ContentString: \n",
      "ToolCalls: [{'name': 'set_priorities', 'args': {}, 'id': 'call_SFU7LwVGHgP1ANDZg0RKrVIQ', 'type': 'tool_call'}]\n"
     ]
    }
   ],
   "source": [
    "response = model_with_tools.invoke([HumanMessage(content=\"can you set my priorities\")])\n",
    "\n",
    "print(f\"ContentString: {response.content}\")\n",
    "print(f\"ToolCalls: {response.tool_calls}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "31b01cca-7e4c-422a-b509-f5001a0e4a0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[HumanMessage(content='hi!, can you create me a 5 tasks to do list i have sql exam tommorrow, keep answer very very short', additional_kwargs={}, response_metadata={}, id='8c1ca446-2e85-4688-848a-f2dfd18a1577'),\n",
       " AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_CAsVT8hervE5EaRuGjdYMWfm', 'function': {'arguments': '{\"tasks_completed\":\"\",\"subject\":\"SQL\",\"roadmap\":\"1. Review SQL basics\\\\n2. Practice sample queries\\\\n3. Study key functions and commands\\\\n4. Take a mock test\\\\n5. Revise notes\"}', 'name': 'create_todolist'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 55, 'prompt_tokens': 110, 'total_tokens': 165, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_44added55e', 'id': 'chatcmpl-BMAmxJwWdL0axcJp2MtQ7kjBLR6zj', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-aedbb7e9-82d6-400d-8d9c-da98720763a8-0', tool_calls=[{'name': 'create_todolist', 'args': {'tasks_completed': '', 'subject': 'SQL', 'roadmap': '1. Review SQL basics\\n2. Practice sample queries\\n3. Study key functions and commands\\n4. Take a mock test\\n5. Revise notes'}, 'id': 'call_CAsVT8hervE5EaRuGjdYMWfm', 'type': 'tool_call'}], usage_metadata={'input_tokens': 110, 'output_tokens': 55, 'total_tokens': 165, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}),\n",
       " ToolMessage(content='Create a daily todo list based on the  till now based on 1. Review SQL basics\\n2. Practice sample queries\\n3. Study key functions and commands\\n4. Take a mock test\\n5. Revise notes provided for the user.', name='create_todolist', id='cdae972f-42ec-4df6-bbee-94a6ec1b6750', tool_call_id='call_CAsVT8hervE5EaRuGjdYMWfm'),\n",
       " AIMessage(content='Hereâ€™s your 5-task to-do list for SQL exam preparation:\\n\\n1. Review SQL basics  \\n2. Practice sample queries  \\n3. Study key functions and commands  \\n4. Take a mock test  \\n5. Revise notes', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 48, 'prompt_tokens': 224, 'total_tokens': 272, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_44added55e', 'id': 'chatcmpl-BMAn00iVRpDps5bA3VJ9JtBM2uJtm', 'finish_reason': 'stop', 'logprobs': None}, id='run-d949cc46-5ab4-4b6e-aebc-55a8498795a3-0', usage_metadata={'input_tokens': 224, 'output_tokens': 48, 'total_tokens': 272, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langgraph.prebuilt import create_react_agent\n",
    "\n",
    "agent_executor = create_react_agent(model, tools)\n",
    "\n",
    "response = agent_executor.invoke({\"messages\": [HumanMessage(content=\"hi!, can you create me a 5 tasks to do list i have sql exam tommorrow, keep answer very very short\")]})\n",
    "\n",
    "response[\"messages\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a0001d16-f3ca-401c-828c-a5c91da729be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Hereâ€™s your 5-task to-do list for SQL exam preparation:\n",
      "\n",
      "1. Review SQL basics  \n",
      "2. Practice sample queries  \n",
      "3. Study key functions and commands  \n",
      "4. Take a mock test  \n",
      "5. Revise notes\n"
     ]
    }
   ],
   "source": [
    "response[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8dae198-1807-47a6-8e86-08f62570cffa",
   "metadata": {},
   "source": [
    "How to create tools and search using tools has been Completed, Now next step is to save memory in the langchain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14dc2d7f-19d8-4b9c-bf54-a8f819d52644",
   "metadata": {},
   "source": [
    "### Adding in Memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "cf7505ce-7358-4597-9ffb-181eea07dbeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "\n",
    "memory = MemorySaver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "02ae1e52-178c-453c-b6be-9431f826819d",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_executor = create_react_agent(model= llm_model, tools= tools, checkpointer= memory)\n",
    "\n",
    "config = {\"configurable\": {\"thread_id\": \"abc123\"}}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f10a5d1-6b95-4fd9-adce-93bb05ea94d4",
   "metadata": {},
   "source": [
    "To give it memory we need to pass in a checkpointer. When passing in a checkpointer, we also have to pass in a thread_id when invoking the agent (so it knows which thread/conversation to resume from)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "2df14ad6-cf97-4ac8-837f-c6cbddbb330b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'agent': {'messages': [AIMessage(content='Hello Sayed Ashfaq! How can I assist you today?', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 15, 'prompt_tokens': 91, 'total_tokens': 106, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_44added55e', 'id': 'chatcmpl-BMAwY8i7vkKPOWV7J3RYYvF14C0qW', 'finish_reason': 'stop', 'logprobs': None}, id='run-1e37abe3-9f57-45c7-bb48-8fa7efbad11b-0', usage_metadata={'input_tokens': 91, 'output_tokens': 15, 'total_tokens': 106, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]}}\n",
      "_______\n"
     ]
    }
   ],
   "source": [
    "for chunk in agent_executor.stream({\"messages\": [HumanMessage(content= \"hi i am sayed ashfaq\")]}, config):\n",
    "    \n",
    "    print(chunk)\n",
    "    print(\"_______\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32d6b364-bce5-4ee9-9abd-7872c34bfa3b",
   "metadata": {},
   "source": [
    "**In the above code memory is stored in a thread, if you want a fresh memory then change the thread id and everything else is same**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2b114da-c589-447e-adb0-2d68236434a3",
   "metadata": {},
   "source": [
    "### Long term Memory from DeepLearnign.AI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "c3e1cc83-d7f2-4501-98fc-5c59893de4a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "profile = {\n",
    "    \"name\": \"John\",\n",
    "    \"full_name\": \"John Doe\",\n",
    "    \"user_profile_background\": \"Senior software engineer leading a team of 5 developers\",\n",
    "}\n",
    "\n",
    "prompt_instructions = {\n",
    "    \"triage_rules\": {\n",
    "        \"ignore\": \"Marketing newsletters, spam emails, mass company announcements\",\n",
    "        \"notify\": \"Team member out sick, build system notifications, project status updates\",\n",
    "        \"respond\": \"Direct questions from team members, meeting requests, critical bug reports\",\n",
    "    },\n",
    "    \"agent_instructions\": \"Use these tools when appropriate to help manage John's tasks efficiently.\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "b960e451-8edb-448c-87f0-6a9b9b722692",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.store.memory import InMemoryStore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "957dcd5a-ee74-41c0-a667-f5fdc55800b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\302sy\\anaconda3\\Lib\\site-packages\\langgraph\\store\\base\\embed.py:95: LangChainBetaWarning: The function `init_embeddings` is in beta. It is actively being worked on, so the API may change.\n",
      "  return init_embeddings(embed)\n"
     ]
    }
   ],
   "source": [
    "store = InMemoryStore(\n",
    "    index= {\"embed\": \"openai: text-embedding-3-small\"}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "28ed1501-15ea-495b-87d4-5f1a0f613d17",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langmem import create_manage_memory_tool, create_search_memory_tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "204ea440-38bb-4109-b479-bacc6d64cc51",
   "metadata": {},
   "outputs": [],
   "source": [
    "manage_memory_tool = create_manage_memory_tool(\n",
    "    namespace=(\n",
    "        \"Personal Assistant\",\n",
    "        \"{langgraph_user_id}\",\n",
    "        \"collection\"\n",
    "        \n",
    "    )\n",
    ")\n",
    "search_memory_tool = create_search_memory_tool(\n",
    "    namespace=(\n",
    "        \"Personal Assistant\",\n",
    "        \"{langgraph_user_id}\",## \n",
    "        \"collection\"\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "e5bbdf57-f959-4d55-8bcf-88e5c3e2476d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'manage_memory'"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "manage_memory_tool.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "c90786e0-4be1-43d8-b713-fc43894b596b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create, update, or delete a memory to persist across conversations.\n",
      "Include the MEMORY ID when updating or deleting a MEMORY. Omit when creating a new MEMORY - it will be created for you.\n",
      "Proactively call this tool when you:\n",
      "\n",
      "1. Identify a new USER preference.\n",
      "2. Receive an explicit USER request to remember something or otherwise alter your behavior.\n",
      "3. Are working and want to record important context.\n",
      "4. Identify that an existing MEMORY is incorrect or outdated.\n"
     ]
    }
   ],
   "source": [
    "print(manage_memory_tool.description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "e3936d13-2486-498c-9484-cd06279fab97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'content': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "  'default': None,\n",
       "  'title': 'Content'},\n",
       " 'action': {'default': 'create',\n",
       "  'enum': ['create', 'update', 'delete'],\n",
       "  'title': 'Action',\n",
       "  'type': 'string'},\n",
       " 'id': {'anyOf': [{'format': 'uuid', 'type': 'string'}, {'type': 'null'}],\n",
       "  'default': None,\n",
       "  'title': 'Id'}}"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "manage_memory_tool.args ## memory is managed by ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "be27fbc9-9aff-47da-acce-b8bb62049467",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Search your long-term memories for information relevant to your current context.\n"
     ]
    }
   ],
   "source": [
    "print(search_memory_tool.description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "7acba1a1-3667-4da0-8309-2218487a97d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'query': {'title': 'Query', 'type': 'string'},\n",
       " 'limit': {'default': 10, 'title': 'Limit', 'type': 'integer'},\n",
       " 'offset': {'default': 0, 'title': 'Offset', 'type': 'integer'},\n",
       " 'filter': {'anyOf': [{'type': 'object'}, {'type': 'null'}],\n",
       "  'default': None,\n",
       "  'title': 'Filter'}}"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search_memory_tool.args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "d190c34b-dfad-4c36-83c7-b8a2747b86b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_system_prompt_memory = \"\"\"\n",
    "< Role >\n",
    "You are {full_name}'s Personal assistant. You are a top-notch personal assistant who cares about {name} performing as well as possible.\n",
    "</ Role >\n",
    "\n",
    "< Tools >\n",
    "You have access to the following tools to help manage {name}'s Goals and daily tasks:\n",
    "\n",
    "1. create_to_list(completed, Goal) - Get the tasks to do for the current day based on {name}'s Goal.\n",
    "2. schedule_meeting(attendees, subject, duration_minutes, preferred_day) - Schedule calendar meetings\n",
    "3. check_calendar_availability(day) - Check available time slots for a given day\n",
    "4. manage_memory - Store any relevant information about contacts, actions, discussion, etc. in memory for future reference\n",
    "5. search_memory - Search for any relevant information that may have been stored in memory\n",
    "</ Tools >\n",
    "\n",
    "< Instructions >\n",
    "{instructions}\n",
    "</ Instructions >\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "055f7392-d9b1-4490-ba12-f3a865f842c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_prompt(state):\n",
    "    return [\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": agent_system_prompt_memory.format(\n",
    "                instructions= prompt_instructions[\"agent_instructions\"],\n",
    "                **profile ##used to unpack a dictionary\n",
    "                \n",
    "            )\n",
    "        }\n",
    "    ] + state['messages']\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "ace6d671-67a2-48ee-b473-8cbe03efecba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Use these tools when appropriate to help manage John's tasks efficiently.\""
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt_instructions[\"agent_instructions\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "cda06464-3a6a-4767-8637-11fae67cd139",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: Alice, Age: 30\n"
     ]
    }
   ],
   "source": [
    "##EXAMPLE\n",
    "\n",
    "profile1 = {\"name\": \"Alice\", \"age\": 30}\n",
    "print(\"Name: {name}, Age: {age}\".format(**profile1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "c6d3aea5-5373-44ca-96f3-f694d5b34539",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.prebuilt import create_react_agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "64c05682-7bfb-4ff2-a6b1-ebaa40f3255e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tools= [\n",
    "    create_todolist, \n",
    "    schedule_meeting,\n",
    "    check_calendar_availability,\n",
    "    manage_memory_tool,\n",
    "    search_memory_tool\n",
    "]\n",
    "response_agent = create_react_agent(model= llm_model,\n",
    "    tools=tools,\n",
    "    prompt=create_prompt,\n",
    "    # Use this to ensure the store is passed to the agent \n",
    "    store=store\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "dc3527e8-8c6d-4c14-8fb5-4b17e1ff3d58",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\"configurable\": {\"langgraph_user_id\": \"abc123\"}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "98db0372-0d9c-4a21-82ff-18d16e87d0f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = response_agent.invoke(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": \"I am 23 years old and i want to become a millionaire by 30\"}]},\n",
    "    config=config\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "3c652a7e-2d04-4c9c-ac3a-28b9151f9ce0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "I am 23 years old and i want to become a millionaire by 30\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  manage_memory (call_BDf9RiURrftxbUzkToEkgDzW)\n",
      " Call ID: call_BDf9RiURrftxbUzkToEkgDzW\n",
      "  Args:\n",
      "    content: Sayed Ashfaq is 23 years old and wants to become a millionaire by 30.\n",
      "    action: create\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: manage_memory\n",
      "\n",
      "created memory a0956632-8869-40f3-8a45-9b1a67eaf1cf\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "That's an ambitious goal! To help you on this journey, we can create a plan with specific goals and tasks to work towards becoming a millionaire by 30. We could focus on strategies like saving, investing, generating additional income, or pursuing entrepreneurial endeavors. \n",
      "\n",
      "What area are you most interested in focusing on first?\n"
     ]
    }
   ],
   "source": [
    "for m in response['messages']:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "54962a76-1612-4bec-a1fa-38420f55028c",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = response_agent.invoke(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": \"what is my goal in one line\"}]},\n",
    "    config=config\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "bb2a0ef7-26c2-4ee6-a65c-4352b6a63113",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "what is my goal in one line\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  search_memory (call_m9M27h0iC2a5IHxY9YrFH9iZ)\n",
      " Call ID: call_m9M27h0iC2a5IHxY9YrFH9iZ\n",
      "  Args:\n",
      "    query: goal\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: search_memory\n",
      "\n",
      "[{\"namespace\":[\"Personal Assistant\",\"abc123\",\"collection\"],\"key\":\"a0956632-8869-40f3-8a45-9b1a67eaf1cf\",\"value\":{\"content\":\"Sayed Ashfaq is 23 years old and wants to become a millionaire by 30.\"},\"created_at\":\"2025-04-14T11:16:08.252258+00:00\",\"updated_at\":\"2025-04-14T11:16:08.252258+00:00\",\"score\":0.20897611726197557},{\"namespace\":[\"Personal Assistant\",\"abc123\",\"collection\"],\"key\":\"8a6bd314-4573-468d-8100-2f139f6461b5\",\"value\":{\"content\":\"Jim is Sayed Ashfaq's friend.\"},\"created_at\":\"2025-04-14T11:14:57.086605+00:00\",\"updated_at\":\"2025-04-14T11:14:57.086605+00:00\",\"score\":0.15085248350681868}]\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Your goal is to become a millionaire by the age of 30.\n"
     ]
    }
   ],
   "source": [
    "for m in response['messages']:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b16b2ffe-fc17-4af1-941e-4cfdba44bc29",
   "metadata": {},
   "source": [
    "**Try getting longer text like getting a roadmap - then store it - then get the response like what am i supposed to do in 4th month**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "3843d3d1-0f76-447d-9e38-6afa95004ef3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Personal Assistant', 'abc123', 'collection')]"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "store.list_namespaces()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "8ee10b64-705c-4d9e-b995-463fa359a5fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Item(namespace=['Personal Assistant', 'abc123', 'collection'], key='8a6bd314-4573-468d-8100-2f139f6461b5', value={'content': \"Jim is Sayed Ashfaq's friend.\"}, created_at='2025-04-14T11:14:57.086605+00:00', updated_at='2025-04-14T11:14:57.086605+00:00', score=None),\n",
       " Item(namespace=['Personal Assistant', 'abc123', 'collection'], key='a0956632-8869-40f3-8a45-9b1a67eaf1cf', value={'content': 'Sayed Ashfaq is 23 years old and wants to become a millionaire by 30.'}, created_at='2025-04-14T11:16:08.252258+00:00', updated_at='2025-04-14T11:16:08.252258+00:00', score=None)]"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "store.search(('Personal Assistant', 'abc123', 'collection'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21a50a0b-e1b3-425d-a868-1e4d5bde1317",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4589f1d-b4ab-43ef-9417-1a5604d89b45",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07126089-b6a0-40a0-9cf5-63309bf533bb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f83c33b-6a9c-4b8c-ac26-2dd46e4d7f9b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "86accb6b-1c26-44a1-a51f-df5300668cf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "1c492739-943d-4bff-a096-9a07b7ca7f55",
   "metadata": {},
   "outputs": [],
   "source": [
    "profile = {\n",
    "    \"name\": \"Sayed\",\n",
    "    \"full_name\" : \"Sayed Ashfaq\",\n",
    "    \"age\" : 23,\n",
    "    \"user_profile\": \"Data Analyst with 2 years of experience\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fd7ef939-494c-40b3-b2c8-ed6a0163fd09",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_instructions= {\n",
    "    \"triage_rules\":{\n",
    "        \"Goal\": \"help him to guide to become a millionaire by the age 30\",\n",
    "        \"assign\": \"From the long term goal - break it into chunks doable tasks and send it to him as daily do list\"\n",
    "    },\n",
    "    \"agent_instructions\": \"Use these tools when appropriate to help the user\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5c95708b-ac5f-4b46-b3e5-5b5257141cfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "profile = {\n",
    "    \"name\": \"John\",\n",
    "    \"full_name\": \"John Doe\",\n",
    "    \"user_profile_background\": \"Senior software engineer leading a team of 5 developers\",\n",
    "}\n",
    "\n",
    "# separated because this is the memory that we are not going to update anytime, it is fixed memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "03152496-dbe1-4093-80bd-6c87e8fdc192",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_instructions = {\n",
    "    \"triage_rules\": {\n",
    "        \"ignore\": \"Marketing newsletters, spam emails, mass company announcements\",\n",
    "        \"notify\": \"Team member out sick, build system notifications, project status updates\",\n",
    "        \"respond\": \"Direct questions from team members, meeting requests, critical bug reports\",\n",
    "    },\n",
    "    # instruction for main agent\n",
    "    \"agent_instructions\": \"Use these tools when appropriate to help manage John's tasks efficiently.\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ea3bd347-3efb-426f-9270-6852077c36e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example incoming email\n",
    "email = {\n",
    "    \"from\": \"Alice Smith <alice.smith@company.com>\",\n",
    "    \"to\": \"John Doe <john.doe@company.com>\",\n",
    "    \"subject\": \"Quick question about API documentation\",\n",
    "    \"body\": \"\"\"\n",
    "Hi John,\n",
    "\n",
    "I was reviewing the API documentation for the new authentication service and noticed a few endpoints seem to be missing from the specs. Could you help clarify if this was intentional or if we should update the docs?\n",
    "\n",
    "Specifically, I'm looking at:\n",
    "- /auth/refresh\n",
    "- /auth/validate\n",
    "\n",
    "Thanks!\n",
    "Alice\"\"\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3b58a2f9-4bd2-4905-8bd3-d7a14b30cf2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "from typing_extensions import TypedDict, Literal, Annotated\n",
    "from langchain.chat_models import init_chat_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bddf3243-ba03-4a21-9a2d-487bf4819d48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<function init_chat_model at 0x00000261CA72DD00>\n"
     ]
    }
   ],
   "source": [
    "print(init_chat_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "568dac37-cc43-415d-b2e6-83825875af31",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm= init_chat_model(\"openai:gpt-4o-mini\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "188c8f7e-ac9b-46ee-b911-b452790a0135",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Router(BaseModel):\n",
    "    \"\"\"Analyze the unread email and route it according to its content.\"\"\"\n",
    "    reasoning: str= Field(\n",
    "        description= \"step-by-step reasoning behind the classification\"\n",
    "    )\n",
    "    classification: Literal[\"ignore\", \"respond\", \"notify\"] = Field(\n",
    "        description= \"The classification of an email: 'ignore' for irrelevant emails, \"\n",
    "        \"'notify' for important information that doesn't need a response, \"\n",
    "        \"'respond' for emails that need a reply\",\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4343577f-cd95-4d92-a3cc-2a6204d337f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_router= llm.with_structured_output(Router)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e63900fa-33c6-4f44-a503-e8c3b151c524",
   "metadata": {},
   "source": [
    "## Create a prompts module for the specific Goal you have, these module includes the prompts of all kinds of memories which are\n",
    "1. sematic - fact based\n",
    "2. Episodic - Experience based\n",
    "3. Procedural - Rule based"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "888eab98-5cef-4b04-bc07-3c6fc746fd71",
   "metadata": {},
   "outputs": [],
   "source": [
    "## import prompts for the triage step\n",
    "\n",
    "from prompts import triage_system_prompt,triage_user_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e0782830-5672-4218-bb8a-a0cf90221518",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "< Role >\n",
      "You are {full_name}'s executive assistant. You are a top-notch executive assistant who cares about {name} performing as well as possible.\n",
      "</ Role >\n",
      "\n",
      "< Background >\n",
      "{user_profile_background}. \n",
      "</ Background >\n",
      "\n",
      "< Instructions >\n",
      "\n",
      "{name} gets lots of emails. Your job is to categorize each email into one of three categories:\n",
      "\n",
      "1. IGNORE - Emails that are not worth responding to or tracking\n",
      "2. NOTIFY - Important information that {name} should know about but doesn't require a response\n",
      "3. RESPOND - Emails that need a direct response from {name}\n",
      "\n",
      "Classify the below email into one of these categories.\n",
      "\n",
      "</ Instructions >\n",
      "\n",
      "< Rules >\n",
      "Emails that are not worth responding to:\n",
      "{triage_no}\n",
      "\n",
      "There are also other things that {name} should know about, but don't require an email response. For these, you should notify {name} (using the `notify` response). Examples of this include:\n",
      "{triage_notify}\n",
      "\n",
      "Emails that are worth responding to:\n",
      "{triage_email}\n",
      "</ Rules >\n",
      "\n",
      "< Few shot examples >\n",
      "{examples}\n",
      "</ Few shot examples >\n"
     ]
    }
   ],
   "source": [
    "print(triage_system_prompt)\n",
    "\n",
    "# curly brackets in the promtp: {empty values to be filled}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "29f2d479-1363-4173-a1c7-49d65d1510e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fill values in the curly brackets\n",
    "system_prompt = triage_system_prompt.format(\n",
    "    full_name= profile[\"full_name\"],\n",
    "    name= profile['name'],\n",
    "    examples= None,\n",
    "    user_profile_background= profile[\"user_profile_background\"],\n",
    "    triage_no= prompt_instructions['triage_rules'][\"ignore\"],\n",
    "    triage_notify= prompt_instructions['triage_rules'][\"notify\"],\n",
    "    triage_email= prompt_instructions['triage_rules'][\"respond\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "743158fb-5933-44aa-b263-26fe0e5f3947",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_instructions = {\n",
    "    \"triage_rules\": {\n",
    "        \"ignore\": \"Marketing newsletters, spam emails, mass company announcements\",\n",
    "        \"notify\": \"Team member out sick, build system notifications, project status updates\",\n",
    "        \"respond\": \"Direct questions from team members, meeting requests, critical bug reports\",\n",
    "    },\n",
    "    \"agent_instructions\": \"Use these tools when appropriate to help manage John's tasks efficiently.\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e57cd218-0ace-4a08-92db-2666c79bbc37",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_prompt = triage_user_prompt.format(\n",
    "    author=email[\"from\"],\n",
    "    to=email[\"to\"],\n",
    "    subject=email[\"subject\"],\n",
    "    email_thread=email[\"body\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39f3028f-fa6d-4234-8007-65ab2dea1044",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "967fc833-f2fe-47d5-aabf-1332d7ad1083",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### GIVEN BY ANACONDA #####\n",
    "# # Import relevant functionality\n",
    "# from langchain_anthropic import ChatAnthropic\n",
    "# from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "# from langchain_core.messages import HumanMessage\n",
    "# from langgraph.checkpoint.memory import MemorySaver\n",
    "# from langgraph.prebuilt import create_react_agent\n",
    "\n",
    "# # Create the agent\n",
    "# memory = MemorySaver()\n",
    "# model = ChatAnthropic(model_name=\"claude-3-sonnet-20240229\")\n",
    "# search = TavilySearchResults(max_results=2)\n",
    "# tools = [search]\n",
    "# agent_executor = create_react_agent(model, tools, checkpointer=memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4a4e6c3-15bb-4065-9e19-9dd1ef9a82e5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a11457db-2ba6-4f2f-a6e4-36f7bdb72d10",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca2780b5-cbd3-4477-bb52-1dcc2bc554bd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
